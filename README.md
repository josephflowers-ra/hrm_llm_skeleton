
---

# HRM-LLM Hybrid

## Overview

This repository implements a **Hierarchical Reasoning Model (HRM)** controller on top of a **frozen language model (LLM)**. The LLM provides fluent text generation, while HRM contributes structured latent reasoning in hidden space.

Unlike standard Chain-of-Thought prompting (which externalizes reasoning into text), HRM enables the system to **â€œthink silentlyâ€ in hidden states** before producing an answer. This yields deeper, more reliable reasoning without long token chains.

Key ingredients:

* **Frozen Hugging Face LLM** (TinyLlama, Qwen, etc.)
* **Hierarchical Reasoning Model (HRM)**: coupled high-level (H) and low-level (L) recurrent modules.
* **Injectors** (GRB or CAB) to bias LLM hidden states with HRMâ€™s latent reasoning output.
* **Optional ACT halting** (q-head) to adapt reasoning depth per query.
* **Reasoning-Gym datasets** for arithmetic, equations, and symbolic tasks.
* **Minimal training harness** with deep supervision, spot-check logging, and inference-time scaling.

---

## Quick Results

Our first stable training run (â‰ˆ **50,000 steps**) with a frozen **TinyLlama** backbone + **HRM controller** reached:

* **Proxy Eval Accuracy:** \~**95%** (n=200, greedy decode)
* **Tasks:** arithmetic (addition, subtraction, equations, GSM symbolic mix)
* **z\_H mean norm:** \~13
* **Training Loss:** fell to near-zero on supervised segments
* **Spot-check outputs:** exact numeric answers, EOS termination


### Current HRMConfig

```python
class HRMConfig:
    # Latent width / depth
    d_h: int = 512
    h_layers: int = 4
    l_layers: int = 4
    n_heads: int = 8

    # Unrolled dynamics
    inner_T: int = 3
    segments: int = 3

    # Bridges / options
    use_cab: bool = False     # False â†’ GRB, True â†’ CAB
    use_act: bool = False

    # Small vocab-bias head (z_H â†’ logits bias), gated
    logit_bias_head: bool = True
    logit_bias_init: float = -2.0  # sigmoid(-2) â‰ˆ 0.12 initial strength

    # Label masking for CE
    vocab_ignore_index: int = -100
```

### Approximate Model Size

* **Base LLM (frozen):** TinyLlama-1.1B (\~1.1B params)
* **HRM controller + injectors + bias head:** \~**25â€“30M params** (depending on hidden size and CAB mem tokens)
* **Total trainable parameters:** \~**30M** (â‰ˆ 3% of backbone)

---

---
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                        Input Text                        â”‚
            â”‚                (prompt; decode settings)                 â”‚
            â”‚            T=1.0 | top_p=0.0 | top_k=0 (greedy)          â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                  Frozen LLM (encoder)                    â”‚
            â”‚  - Run prompt (and growing decode context)               â”‚
            â”‚  - Collect last hidden states h âˆˆ â„^{BÃ—TÃ—D_model}        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                 Pool ONLY the prompt region per sample
                    (mean + last) â†’ linear mix â†’ x_pool
                            â”‚
                            â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚          Project to HRM width: xÌƒ = W_proj(x_pool)        â”‚
            â”‚                    xÌƒ âˆˆ â„^{BÃ—1Ã—d_h}                       â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚            HRM Reasoning Loop                            â”‚
         â”‚     (low-level fast L; high-level H)                     â”‚
         â”‚                                                          â”‚
         â”‚  for segment m = 1..M (or until ACT halts):              â”‚   
         â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚   â”‚   L-block (fast)                                  â”‚  â”‚
         â”‚   â”‚   - do inner_T-1 micro-steps (no_grad)            â”‚  â”‚
         â”‚   â”‚   - 1 final micro-step (with grad)                â”‚  â”‚
         â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â”‚               â”‚                                          â”‚
         â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚   â”‚   H-block (slow)                                  â”‚  â”‚
         â”‚   â”‚   - update z_H from z_L                           â”‚  â”‚
         â”‚   â”‚   - RMSNorm on z_H                                â”‚  â”‚
         â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â”‚               â”‚                                          â”‚
         â”‚      (optional) ACT / q-head on z_H                      â”‚
         â”‚               â”‚                                          â”‚
         â”‚      if ACT says â€œhaltâ€: break                           â”‚
         â”‚      else: detach(z_H, z_L) and continue                 â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚   final z_H (shape: BÃ—1Ã—d_h)
                            â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                 Injector Module (LLM side)               â”‚
            â”‚  Option A: GRB (z_H â†’ bias in hidden space, gated)       â”‚
            â”‚  Option B: CAB with multi-token memory (mâ‰¥1), gated      â”‚
            â”‚   - Build z_H-derived memory bank (BÃ—mÃ—D_model)          â”‚
            â”‚   - Cross-attend from token states to memory             â”‚
            â”‚   - Residual add with sigmoid(gate)                      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    Conditioned hidden states h'
                            â”‚
                            â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚        (if present) Final Norm of base LLM               â”‚
            â”‚  e.g., LLaMA/Mistral: model.norm; NeoX: final_layer_norm â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                LLM LM Head â†’ logits (BÃ—TÃ—V)              â”‚
            â”‚  + Gated vocab-bias from z_H (tiny linear, optional)     â”‚
            â”‚      logits += Ïƒ(vocab_gate) Â· W_vocab(z_H)              â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    Select next token (greedy / sampling)
                            â”‚
                            â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚            Append token, update context T                â”‚
            â”‚        If EOS reached or max_len: stop decode            â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜





---

## Motivation

Current LLMs excel at language but struggle with robust, multi-step reasoning. Chain-of-Thought (CoT) prompting helps, but it is:

* **Brittle**: a single token error can derail the whole chain.
* **Data-hungry**: requires many demonstrations.
* **Slow**: long token chains inflate latency and cost.

HRM provides **latent recurrence** in hidden space instead of tokens:

* **Two timescales** of reasoning:

  * **L-module** (fast, detailed, multiple micro-steps per cycle).
  * **H-module** (slow, abstract, 1 step per cycle).
* **Hierarchical convergence**: the L-module converges locally, then resets under updated guidance from the H-module.
* **O(1) memory training** via one-step gradient + deep supervision.
* **ACT halting**: decide dynamically how many reasoning cycles to run.
* **Inference-time scaling**: increase segments at inference to â€œthink longerâ€ without retraining.

---

## Architecture Overview

The pipeline combines a frozen LLM with HRM reasoning and injects the results back into the LLM hidden space before decoding.

ğŸ‘‰ *(Insert the ASCII diagram we built together here â€” showing Input â†’ Frozen LLM â†’ Pool â†’ HRM Loop â†’ Injector â†’ Norm â†’ LM Head â†’ Output, with ACT/q-head and vocab bias.)*

---

### Components

#### 1. Frozen LLM

* Provides embeddings, hidden states, and LM head.
* Parameters frozen (no fine-tuning required).
* Final normalization layer optionally applied before logits.

#### 2. Pooling & Projection

* Mean+last pooling over **prompt tokens only**.
* Linear projection to HRM dimension (`d_h`, default 512).

#### 3. HRM Core

* **L-block**: runs multiple fast inner steps per segment.
* **H-block**: runs once per segment, steering the L-block across cycles.
* **Hierarchical convergence**: keeps computation active across segments.
* **RMSNorm** applied to z\_H.
* **Deep supervision**: loss applied at each segment, with hidden states detached in between.

#### 4. Injectors

* **GRB (Gated Residual Bias)**: projects z\_H as a bias vector, gated by a learnable sigmoid scalar.
* **CAB (Cross-Attention Bridge)**: treats z\_H as one or more memory tokens; token hidden states attend to it. Multi-token CAB offers stronger conditioning.
* Both support residual gating to prevent destabilization.

#### 5. Optional Heads

* **ACT / q-head**: predicts halt vs. continue from z\_H at each segment. Enables Adaptive Computation Time.
* **Vocab bias head**: adds a gated bias over vocabulary logits from z\_H. Helpful for structured outputs like numbers.

#### 6. Training Procedure

* Cross-entropy loss on target tokens (prompt region masked).
* Optional q-loss for ACT halting.
* Segment-level deep supervision with detach â†’ O(1) memory.
* AdamW optimizer with weight decay.
* Gradient clipping for stability.

---

## Datasets

* **Toy addition / chain sum**
* **Basic arithmetic**
* **Simple equations**
* **GSM symbolic reasoning**

Wrapped with a collator that:

* Tokenizes prompt and target separately.
* Concatenates them with masking (`ignore_index=-100` for prompt region).
* Returns `input_ids`, `attention_mask`, `labels`, `prompt_lengths`, and raw examples (for verifiers).

---

## Training Harness

The provided `train.py` script supports:

* **Arguments**:

  * `--segments`, `--inner_T`: HRM loop depth.
  * `--injector {grb,cab}`: choose injector.
  * `--use_act`, `--act_penalty`: enable ACT/Q-head.
  * `--decode_temperature`, `--decode_top_p`, `--decode_top_k`: sampling options at eval.
  * `--eval_segments`: run deeper reasoning at eval-time.
  * `--grad_clip`: stabilize updates.

* **Logging**:

  * Per-step losses.
  * Per-segment losses and q-losses.
  * Proxy eval accuracy with verifier functions.
  * Spot-check decoded examples with greedy or sampling decode.
  * CSV logging of eval curves.

* **Checkpoints**:

  * Lightweight save of trainable HRM parts + optimizer state.
  * Resume training with `--resume path/to/checkpoint.pt`.

---

## Example Usage

**Arithmetic reasoning (TinyLlama, CAB injector, 2Ã—2 loop):**

```bash
python3 train.py \
  --model_name ./tiny-rl-sft \
  --tasks basic_arithmetic,gsm_symbolic,chain_sum,simple_equations \
  --segments 2 --inner_T 2 \
  --injector cab \
  --batch_size 2 --lr 1e-5 \
  --max_steps 200000 \
  --save_every 10000 \
  --eval_every 500 --eval_n 200 --eval_segments 4 \
  --log_samples_every 500 --max_new_tokens 512
```

---

## Key Properties

âœ… **Latent reasoning**: computation happens in hidden space, not tokens.
âœ… **Constant memory**: deep supervision + one-step gradient avoid BPTT.
âœ… **Inference-time scaling**: simply raise `segments` at eval to think deeper.
âœ… **Optional ACT halting**: saves compute by stopping early.
âœ… **Flexible injectors**: GRB (lightweight) vs CAB (stronger conditioning).
âœ… **Frozen LLM**: no costly full-model fine-tuning.

---

## Limitations & Next Steps

âš ï¸ **Base LLM frozen**: limits synergy; adding LoRA to upper layers may help.
âš ï¸ **Stablemax**: currently approximated with temperature scaling; future work could implement true stablemax.
âš ï¸ **Task coverage**: focused on math/symbolic; needs broader datasets.
âš ï¸ **ACT stability**: q-head halting works but can be finicky; reinforcement-style training could improve.

**Planned extensions:**

* LoRA adapters for partial LLM tuning.
* YAML/JSON configs for reproducible runs.
* Integration with Cogito memory modules (episodic/graph memory).
* Experiments with HRM-only (no LLM) baselines.

---

## References

* Sapient Intelligence. *Hierarchical Reasoning Model*. 2025. [arXiv:2506.21734](https://arxiv.org/abs/2506.21734)&#x20;
* Sapient Intelligence HRM GitHub: [github.com/sapientinc/HRM](https://github.com/sapientinc/HRM)
* Lucidrains experimental HRM repo: [github.com/lucidrains/HRM](https://github.com/lucidrains/HRM)

---


